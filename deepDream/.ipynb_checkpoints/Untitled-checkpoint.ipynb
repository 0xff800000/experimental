{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'moviepy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b8a80df307f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meditor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfunctools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'moviepy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#import moviepy.editor as mpe\n",
    "from functools import partial\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib\n",
    "import os\n",
    "import zipfile\n",
    "import sys\n",
    "\n",
    "def main():\n",
    "\t#Step 1 - download google's pre-trained neural network\n",
    "\turl = 'https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip'\n",
    "\tdata_dir = ''\n",
    "\tmodel_name = os.path.split(url)[-1]\n",
    "\tlocal_zip_file = os.path.join(data_dir, model_name)\n",
    "\tif not os.path.exists(local_zip_file):\n",
    "\t\t# Download\n",
    "\t\tmodel_url = urllib.request.urlopen(url)\n",
    "\t\twith open(local_zip_file, 'wb') as output:\n",
    "\t\t\toutput.write(model_url.read())\n",
    "\t\t# Extract\n",
    "\t\twith zipfile.ZipFile(local_zip_file, 'r') as zip_ref:\n",
    "\t\t\tzip_ref.extractall(data_dir)\n",
    "  \n",
    "\t# start with a gray image with a little noise\n",
    "\timg_noise = np.random.uniform(size=(224,224,3)) + 100.0\n",
    "  \n",
    "\tmodel_fn = 'tensorflow_inception_graph.pb'\n",
    "\t\n",
    "\t#Step 2 - Creating Tensorflow session and loading the model\n",
    "\tgraph = tf.Graph()\n",
    "\tsess = tf.InteractiveSession(graph=graph)\n",
    "\twith tf.gfile.FastGFile(os.path.join(data_dir, model_fn), 'rb') as f:\n",
    "\t\tgraph_def = tf.GraphDef()\n",
    "\t\tgraph_def.ParseFromString(f.read())\n",
    "\tt_input = tf.placeholder(np.float32, name='input') # define the input tensor\n",
    "\timagenet_mean = 117.0\n",
    "\tt_preprocessed = tf.expand_dims(t_input-imagenet_mean, 0)\n",
    "\ttf.import_graph_def(graph_def, {'input':t_preprocessed})\n",
    "\t\n",
    "\tlayers = [op.name for op in graph.get_operations() if op.type=='Conv2D' and 'import/' in op.name]\n",
    "\tfeature_nums = [int(graph.get_tensor_by_name(name+':0').get_shape()[-1]) for name in layers]\n",
    "\t\n",
    "\tprint('Number of layers', len(layers))\n",
    "\tprint('Total number of feature channels:', sum(feature_nums))\n",
    "  \n",
    " #####HELPER FUNCTIONS. I didn't go over these in the video for times sake. They are mostly just formatting functions. Scroll \n",
    " #to the bottom #########################################################################################################\n",
    " ########################################################################################################################\n",
    " ############################################################\n",
    " \n",
    "\t# Helper functions for TF Graph visualization\n",
    "\t#pylint: disable=unused-variable\n",
    "\tdef strip_consts(graph_def, max_const_size=32):\n",
    "\t\t\"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "\t\tstrip_def = tf.GraphDef()\n",
    "\t\tfor n0 in graph_def.node:\n",
    "\t\t\tn = strip_def.node.add() #pylint: disable=maybe-no-member\n",
    "\t\t\tn.MergeFrom(n0)\n",
    "\t\t\tif n.op == 'Const':\n",
    "\t\t\t\ttensor = n.attr['value'].tensor\n",
    "\t\t\t\tsize = len(tensor.tensor_content)\n",
    "\t\t\t\tif size > max_const_size:\n",
    "\t\t\t\t\ttensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "\t\treturn strip_def\n",
    "\t  \n",
    "\tdef rename_nodes(graph_def, rename_func):\n",
    "\t\tres_def = tf.GraphDef()\n",
    "\t\tfor n0 in graph_def.node:\n",
    "\t\t\tn = res_def.node.add() #pylint: disable=maybe-no-member\n",
    "\t\t\tn.MergeFrom(n0)\n",
    "\t\t\tn.name = rename_func(n.name)\n",
    "\t\t\tfor i, s in enumerate(n.input):\n",
    "\t\t\t\tn.input[i] = rename_func(s) if s[0]!='^' else '^'+rename_func(s[1:])\n",
    "\t\treturn res_def\n",
    "\t  \n",
    "\tdef showarray(a):\n",
    "\t\ta = np.uint8(np.clip(a, 0, 1)*255)\n",
    "\t\tplt.imshow(a)\n",
    "\t\tplt.show()\n",
    "\t\t\n",
    "\tdef visstd(a, s=0.1):\n",
    "\t\t'''Normalize the image range for visualization'''\n",
    "\t\treturn (a-a.mean())/max(a.std(), 1e-4)*s + 0.5\n",
    "\t\n",
    "\tdef T(layer):\n",
    "\t\t'''Helper for getting layer output tensor'''\n",
    "\t\treturn graph.get_tensor_by_name(\"import/%s:0\"%layer)\n",
    "\t\n",
    "\tdef render_naive(t_obj, img0=img_noise, iter_n=20, step=1.0):\n",
    "\t\tt_score = tf.reduce_mean(t_obj) # defining the optimization objective\n",
    "\t\tt_grad = tf.gradients(t_score, t_input)[0] # behold the power of automatic differentiation!\n",
    "\t\t\n",
    "\t\timg = img0.copy()\n",
    "\t\tfor _ in range(iter_n):\n",
    "\t\t\tg, _ = sess.run([t_grad, t_score], {t_input:img})\n",
    "\t\t\t# normalizing the gradient, so the same step size should work \n",
    "\t\t\tg /= g.std()+1e-8         # for different layers and networks\n",
    "\t\t\timg += g*step\n",
    "\t\tshowarray(visstd(img))\n",
    "\t\t\n",
    "\tdef tffunc(*argtypes):\n",
    "\t\t'''Helper that transforms TF-graph generating function into a regular one.\n",
    "\t\tSee \"resize\" function below.\n",
    "\t\t'''\n",
    "\t\tplaceholders = list(map(tf.placeholder, argtypes))\n",
    "\t\tdef wrap(f):\n",
    "\t\t\tout = f(*placeholders)\n",
    "\t\t\tdef wrapper(*args, **kw):\n",
    "\t\t\t\treturn out.eval(dict(zip(placeholders, args)), session=kw.get('session'))\n",
    "\t\t\treturn wrapper\n",
    "\t\treturn wrap\n",
    "\t\n",
    "\tdef resize(img, size):\n",
    "\t\timg = tf.expand_dims(img, 0)\n",
    "\t\treturn tf.image.resize_bilinear(img, size)[0,:,:,:]\n",
    "\tresize = tffunc(np.float32, np.int32)(resize)\n",
    "\t\n",
    "\tdef calc_grad_tiled(img, t_grad, tile_size=512):\n",
    "\t\t'''Compute the value of tensor t_grad over the image in a tiled way.\n",
    "\t\tRandom shifts are applied to the image to blur tile boundaries over \n",
    "\t\tmultiple iterations.'''\n",
    "\t\tsz = tile_size\n",
    "\t\th, w = img.shape[:2]\n",
    "\t\tsx, sy = np.random.randint(sz, size=2)\n",
    "\t\timg_shift = np.roll(np.roll(img, sx, 1), sy, 0)\n",
    "\t\tgrad = np.zeros_like(img)\n",
    "\t\tfor y in range(0, max(h-sz//2, sz),sz):\n",
    "\t\t\tfor x in range(0, max(w-sz//2, sz),sz):\n",
    "\t\t\t\tsub = img_shift[y:y+sz,x:x+sz]\n",
    "\t\t\t\tg = sess.run(t_grad, {t_input:sub})\n",
    "\t\t\t\tgrad[y:y+sz,x:x+sz] = g\n",
    "\t\treturn np.roll(np.roll(grad, -sx, 1), -sy, 0)    \n",
    "\n",
    "\t#BACK TO CODE IN THE VIDEO###########################################################################################\n",
    "\t########################################################################################################\n",
    "\t##############################################################################\n",
    "\t\n",
    "\t#CHALLENGE - Write a function that outputs a deep dream video\n",
    "\tdef render_deepdreamvideo(path):\n",
    "\t\tclip = mpe.VideoFileClip(path)\n",
    "\t\tfor frame in clip.iter_frame():\n",
    "\t\t\timg1 = render_deepdream(tf.square(T('mixed4c')), frame)\n",
    "\t\t\timg1.save(newPath,'jpeg')\n",
    "\t\t\tindex = 1\n",
    "\t\t\tnewPath = 'out/DeepDream-'+path.split('.')[0]+str(index) + '.jpeg'\n",
    "\t\t\twhile os.path.exists(newPath):\n",
    "\t\t\t\tnewPath = 'out/DeepDream-'+ path.split('.')[0] + str(index) + '.jpeg'\n",
    "\n",
    "\t\t\n",
    "\tdef render_deepdream(t_obj, img0=img_noise,\n",
    "\t\t\t\t\t\t iter_n=100, step=1.5, octave_n=4, octave_scale=1.4):\n",
    "\t\tt_score = tf.reduce_mean(t_obj) # defining the optimization objective\n",
    "\t\tt_grad = tf.gradients(t_score, t_input)[0] # behold the power of automatic differentiation!\n",
    "\t\n",
    "\t\t# split the image into a number of octaves\n",
    "\t\timg = img0\n",
    "\t\toctaves = []\n",
    "\t\tfor _ in range(octave_n-1):\n",
    "\t\t\thw = img.shape[:2]\n",
    "\t\t\tlo = resize(img, np.int32(np.float32(hw)/octave_scale))\n",
    "\t\t\thi = img-resize(lo, hw)\n",
    "\t\t\timg = lo\n",
    "\t\t\toctaves.append(hi)\n",
    "\t\t\n",
    "\t\t# generate details octave by octave\n",
    "\t\tfor octave in range(octave_n):\n",
    "\t\t\tif octave>0:\n",
    "\t\t\t\thi = octaves[-octave]\n",
    "\t\t\t\timg = resize(img, hi.shape[:2])+hi\n",
    "\t\t\tfor _ in range(iter_n):\n",
    "\t\t\t\tg = calc_grad_tiled(img, t_grad)\n",
    "\t\t\t\timg += g*(step / (np.abs(g).mean()+1e-7))\n",
    "\t\t\t\n",
    "\t\t\t#this will usually be like 3 or 4 octaves\n",
    "\t\t\t#Step 5 output deep dream image via matplotlib\n",
    "\t\tshowarray(img/255)\n",
    "\t\tprint(type(img))\n",
    "\t\tprint(img/255.0)\n",
    "\t\treturn\tPIL.Image.fromarray(np.uint8(img+np.min(img)))\n",
    "\t\t\t\n",
    "\t\t\n",
    "\t#Step 3 - Pick a layer to enhance our image\n",
    "\tlayer = 'mixed4d_3x3_bottleneck_pre_relu'\n",
    "\tchannel = 139 # picking some feature channel to visualize\n",
    "\t\n",
    "\t#open image\n",
    "\tpath = str(sys.argv[1])\n",
    "\timg0 = PIL.Image.open(path)\n",
    "\timg0 = np.float32(img0)\n",
    "\tprint(img0[0])\n",
    "\t#Step 4 - Apply gradient ascent to that layer\n",
    "\timg1 = render_deepdream(tf.square(T('mixed4c')), img0)\n",
    "\t#img1 = PIL.Image.fromarray(img0/255.0)\n",
    "\n",
    "\t# Save image\n",
    "\tnewPath = 'DeepDream-'+path.split('.')[0] + '.jpeg'\n",
    "\tindex = 1\n",
    "\twhile os.path.exists(newPath):\n",
    "\t\tnewPath = 'DeepDream-'+ path.split('.')[0] + str(index) + '.jpeg'\n",
    "\t\tindex+=1\n",
    "\n",
    "\timg1.save(newPath,'jpeg')\n",
    "\t  \n",
    "  \n",
    "if __name__ == '__main__':\n",
    "\tmain()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
